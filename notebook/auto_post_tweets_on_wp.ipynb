{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlencode\n",
    "from urllib.parse import urljoin\n",
    "from datetime import datetime\n",
    "from requests_oauthlib import OAuth1\n",
    "import requests\n",
    "import copy\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_be_set = {\n",
    "    'YEAR': '2020',\n",
    "    'S_MONTH': '06',\n",
    "    'S_DATE': '01',\n",
    "    'E_MONTH': '06',\n",
    "    'E_DATE': '09',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # Secret key of Twitter API\n",
    "    'CONSUMER_KEY': 'foLsfclN3YXISSrstIqdzGmri',\n",
    "    'CONSUMER_SECRET_KEY': 'D5EoS9E6eQRUdhHBQSCv6rVgutu9EhunnCww6iNJfoyrtvPYMG',\n",
    "    'ACCESS_TOKEN': '4096685054-24InfHUvJzq14IYz8g7wCXmVaQwLDxzyzYDtKQ1',\n",
    "    'ACCESS_TOKEN_SECRET': 'V3Q1q5MTStmHBUTiHYBFftEBXLXxWe7LnaJnUlLZ5eVPH',\n",
    "    \n",
    "    # Request parameters for Twitter API\n",
    "    'ROOT_URL': 'https://api.twitter.com/1.1/search/tweets.json?',\n",
    "    'LANG': ['ja', 'en'],\n",
    "    'TWEET_TYPE': 'extended',\n",
    "    'COUNT': 100,  # the number of response per one request (max 100, default is 15)\n",
    "    'RANGE': 10,  # the number of request (max 180/15minutes)\n",
    "    'RESULT_TYPE': 'popular',  # popular or mixed or recent\n",
    "    'WORDS':  ['\\\"„Éá„Éº„Çø„Çµ„Ç§„Ç®„É≥„Çπ\\\"', '\\\"Ê©üÊ¢∞Â≠¶Áøí\\\"', '\\\"data science\\\"', '\\\"machine learning\\\"'],\n",
    "    'SINCE': '{}-{}-{}'.format(params_to_be_set['YEAR'], params_to_be_set['S_MONTH'], params_to_be_set['S_DATE']),\n",
    "    'UNTIL': '{}-{}-{}'.format(params_to_be_set['YEAR'], params_to_be_set['E_MONTH'], params_to_be_set['E_DATE']),\n",
    "    \n",
    "    # parameters for Wordpress\n",
    "    'WP_URL': 'https://hophead-ds.com',\n",
    "    'WP_USERNAME': 'user',\n",
    "    'WP_PASSWORD': 'oAVL oteM IlaB cTdi gmF6 5MMP',\n",
    "    'STATUS': 'draft',\n",
    "    'CATEGORY': [5],\n",
    "    'SLUG': '{}/{}/{}/twitter/auto_post'.format(params_to_be_set['YEAR'], params_to_be_set['E_MONTH'], params_to_be_set['E_DATE']),\n",
    "    'TITLE': '„Éá„Éº„Çø„Çµ„Ç§„Ç®„É≥„Çπ„ÉªÊ©üÊ¢∞Â≠¶Áøí Twiiter ÊäïÁ®ø„Åæ„Å®„ÇÅ {}/{}/{}-{}/{}/{}'.format(\n",
    "        params_to_be_set['YEAR'], params_to_be_set['S_MONTH'], params_to_be_set['S_DATE'], \n",
    "        params_to_be_set['YEAR'], params_to_be_set['E_MONTH'], params_to_be_set['E_DATE']\n",
    "    ),\n",
    "    'TAG_IDS': [],\n",
    "    'MEDIA_ID': None,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search popular tweets I'm interested in.\n",
    "\n",
    "- API reference: http://westplain.sakuraweb.com/translate/twitter/Documentation/REST-APIs/Public-API/GET-search-tweets.cgi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tweets(params, debug=False):\n",
    "    tweets = []\n",
    "    auth = OAuth1(\n",
    "        params['CONSUMER_KEY'],\n",
    "        params['CONSUMER_SECRET_KEY'],\n",
    "        params['ACCESS_TOKEN'],\n",
    "        params['ACCESS_TOKEN_SECRET']\n",
    "    )\n",
    "    \n",
    "    for lang in params['LANG']:\n",
    "        for word in params['WORDS']:\n",
    "            cnt = 0\n",
    "            print(lang, word)\n",
    "            word += ' exclude:retweets exclude:replies'\n",
    "\n",
    "            while True:\n",
    "                if cnt > params['RANGE']:\n",
    "                    break\n",
    "\n",
    "                if cnt == 0:\n",
    "                    url_args = urlencode({\n",
    "                        'lang': lang,\n",
    "                        'q': word,\n",
    "                        'count': str(params['COUNT']),\n",
    "                        'result_type': params['RESULT_TYPE'],\n",
    "                        'tweet_mode':params['TWEET_TYPE'],\n",
    "                        'since': params['SINCE'],\n",
    "                        'until': params['UNTIL'],\n",
    "                    })\n",
    "                    response = requests.get(url=params['ROOT_URL'] + url_args, auth=auth)\n",
    "                    data = response.json()['statuses']\n",
    "                    if len(data) == 0:\n",
    "                        break\n",
    "                else:\n",
    "                    for tweet in data:\n",
    "                        max_id = int(tweet['id']) - 1\n",
    "                        if tweet in tweets:\n",
    "                            continue\n",
    "                        tweets.append(tweet)\n",
    "                        if debug:\n",
    "                            print('For loop: {}, tweet created at: {}'.format(cnt, tweet['created_at']))\n",
    "                    url_args = urlencode({\n",
    "                        'lang': lang,\n",
    "                        'q': word,\n",
    "                        'count': str(params['COUNT']),\n",
    "                        'result_type': params['RESULT_TYPE'],\n",
    "                        'tweet_mode':params['TWEET_TYPE'],\n",
    "                        'since': params['SINCE'],\n",
    "                        'until': params['UNTIL'],\n",
    "                        'max_id': str(max_id),\n",
    "                    })\n",
    "                    response = requests.get(url=params['ROOT_URL'] + url_args, auth=auth)\n",
    "                    try:\n",
    "                        data = response.json()['statuses']\n",
    "                    except KeyError:  # if the number of requests is over the limit.\n",
    "                        print('Error: the number of requests is over the limit.')\n",
    "                        break\n",
    "\n",
    "                cnt += 1\n",
    "\n",
    "    return tweets\n",
    "\n",
    "\n",
    "def prune_query_result(tweet):\n",
    "    tweet_pruned = copy.copy(tweet)\n",
    "    prune_keys = [\n",
    "        'id_str',\n",
    "        'truncated',\n",
    "        'entities',\n",
    "        'extended_entities',\n",
    "        'metadata',\n",
    "        'source',\n",
    "        'in_reply_to_status_id',\n",
    "        'in_reply_to_status_id_str',\n",
    "        'in_reply_to_user_id',\n",
    "        'in_reply_to_user_id_str',\n",
    "        'in_reply_to_screen_name',\n",
    "        'geo',\n",
    "        'coordinates',\n",
    "        'place',\n",
    "        'contributors',\n",
    "        'is_quote_status',\n",
    "        'favorited', \n",
    "        'retweeted', \n",
    "        'possibly_sensitive', \n",
    "        'quoted_status',\n",
    "        'quoted_status_id',\n",
    "        'quoted_status_id_str',\n",
    "        'user',\n",
    "    ]\n",
    "    tweet_pruned['screen_name'] = tweet_pruned['user']['screen_name']\n",
    "    for key in prune_keys:\n",
    "        try:\n",
    "            del tweet_pruned[key]\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return tweet_pruned\n",
    "        \n",
    "def extract_popular_tweets(tweets, threshold=100):\n",
    "    popular_tweets = []\n",
    "    for tweet in tweets:\n",
    "        if tweet['favorite_count']>=threshold:\n",
    "            tweet_pruned = prune_query_result(tweet)\n",
    "            popular_tweets.append(tweet_pruned)\n",
    "    popular_tweets.sort(key=lambda x: x['favorite_count'], reverse=True)\n",
    "    return popular_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ja \"„Éá„Éº„Çø„Çµ„Ç§„Ç®„É≥„Çπ\"\n",
      "For loop: 1, tweet created at: Wed Jun 03 15:19:53 +0000 2020\n",
      "For loop: 1, tweet created at: Wed Jun 03 16:22:07 +0000 2020\n",
      "For loop: 1, tweet created at: Fri Jun 05 04:27:02 +0000 2020\n",
      "ja \"Ê©üÊ¢∞Â≠¶Áøí\"\n",
      "ja \"data science\"\n",
      "ja \"machine learning\"\n",
      "en \"„Éá„Éº„Çø„Çµ„Ç§„Ç®„É≥„Çπ\"\n",
      "en \"Ê©üÊ¢∞Â≠¶Áøí\"\n",
      "en \"data science\"\n",
      "For loop: 1, tweet created at: Mon Jun 08 13:23:00 +0000 2020\n",
      "For loop: 1, tweet created at: Mon Jun 08 10:58:35 +0000 2020\n",
      "For loop: 1, tweet created at: Mon Jun 08 21:00:02 +0000 2020\n",
      "For loop: 1, tweet created at: Mon Jun 08 17:44:30 +0000 2020\n",
      "For loop: 1, tweet created at: Tue Jun 02 00:48:31 +0000 2020\n",
      "For loop: 1, tweet created at: Sat Jun 06 21:18:07 +0000 2020\n",
      "For loop: 1, tweet created at: Sun Jun 07 03:55:03 +0000 2020\n",
      "For loop: 1, tweet created at: Mon Jun 01 14:14:29 +0000 2020\n",
      "For loop: 1, tweet created at: Fri Jun 05 00:52:00 +0000 2020\n",
      "For loop: 1, tweet created at: Fri Jun 05 19:30:00 +0000 2020\n",
      "For loop: 1, tweet created at: Thu Jun 04 16:44:51 +0000 2020\n",
      "For loop: 1, tweet created at: Sat Jun 06 05:01:03 +0000 2020\n",
      "For loop: 1, tweet created at: Fri Jun 05 21:00:00 +0000 2020\n",
      "For loop: 1, tweet created at: Wed Jun 03 06:58:28 +0000 2020\n",
      "For loop: 1, tweet created at: Fri Jun 05 23:08:53 +0000 2020\n",
      "For loop: 2, tweet created at: Wed Jun 03 20:55:28 +0000 2020\n",
      "For loop: 2, tweet created at: Wed Jun 03 05:17:36 +0000 2020\n",
      "For loop: 2, tweet created at: Fri Jun 05 19:47:01 +0000 2020\n",
      "en \"machine learning\"\n",
      "For loop: 1, tweet created at: Mon Jun 08 04:48:47 +0000 2020\n",
      "For loop: 1, tweet created at: Mon Jun 08 15:30:19 +0000 2020\n",
      "For loop: 1, tweet created at: Sun Jun 07 22:44:00 +0000 2020\n",
      "For loop: 1, tweet created at: Sun Jun 07 19:40:00 +0000 2020\n",
      "For loop: 1, tweet created at: Sun Jun 07 16:00:16 +0000 2020\n",
      "For loop: 1, tweet created at: Mon Jun 08 21:21:48 +0000 2020\n",
      "For loop: 1, tweet created at: Mon Jun 08 20:57:19 +0000 2020\n",
      "For loop: 1, tweet created at: Tue Jun 02 18:40:00 +0000 2020\n",
      "For loop: 1, tweet created at: Mon Jun 01 13:08:08 +0000 2020\n",
      "For loop: 1, tweet created at: Tue Jun 02 15:44:42 +0000 2020\n",
      "For loop: 1, tweet created at: Wed Jun 03 15:25:00 +0000 2020\n",
      "For loop: 1, tweet created at: Sat Jun 06 15:00:24 +0000 2020\n",
      "For loop: 1, tweet created at: Wed Jun 03 18:49:02 +0000 2020\n",
      "For loop: 1, tweet created at: Wed Jun 03 22:35:15 +0000 2020\n",
      "For loop: 2, tweet created at: Tue Jun 02 13:51:55 +0000 2020\n",
      "For loop: 2, tweet created at: Mon Jun 01 14:22:23 +0000 2020\n",
      "For loop: 2, tweet created at: Tue Jun 02 21:02:19 +0000 2020\n",
      "For loop: 2, tweet created at: Tue Jun 02 15:10:03 +0000 2020\n",
      "For loop: 2, tweet created at: Mon Jun 01 12:08:10 +0000 2020\n",
      "For loop: 2, tweet created at: Mon Jun 01 15:55:51 +0000 2020\n",
      "For loop: 2, tweet created at: Mon Jun 01 07:10:03 +0000 2020\n",
      "For loop: 2, tweet created at: Wed Jun 03 01:29:48 +0000 2020\n",
      "For loop: 2, tweet created at: Wed Jun 03 16:57:24 +0000 2020\n",
      "For loop: 3, tweet created at: Tue Jun 02 08:30:30 +0000 2020\n"
     ]
    }
   ],
   "source": [
    "tweets = search_tweets(params, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "popular_tweets = extract_popular_tweets(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(popular_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>display_text_range</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>full_text</th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>screen_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wed Jun 03 15:19:53 +0000 2020</td>\n",
       "      <td>[0, 143]</td>\n",
       "      <td>9052</td>\n",
       "      <td>„Ç¢„É°„É™„Ç´„ÅÆ„Éò„É´„Çπ„Ç±„Ç¢‰ºÅÊ•≠„ÅÆÊé°Áî®„ÅåÊ±∫„Åæ„Çä„Åæ„Åó„Åü„ÄÇ\\n\\nÈßÜ„ÅëÂá∫„Åó„Åß„ÅØ„ÅÇ„Çä„Åæ„Åô„Åå„ÄÅ„Éá„Éº„Çø„Çµ„Ç§„Ç®„É≥...</td>\n",
       "      <td>1268200743372275713</td>\n",
       "      <td>ja</td>\n",
       "      <td>559</td>\n",
       "      <td>mph_for_doctors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tue Jun 02 00:48:31 +0000 2020</td>\n",
       "      <td>[0, 228]</td>\n",
       "      <td>3041</td>\n",
       "      <td>No masks. No social distancing. But at least t...</td>\n",
       "      <td>1267619067919245314</td>\n",
       "      <td>en</td>\n",
       "      <td>647</td>\n",
       "      <td>YossiGestetner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wed Jun 03 16:22:07 +0000 2020</td>\n",
       "      <td>[0, 141]</td>\n",
       "      <td>2119</td>\n",
       "      <td>ÁßÅ„ÅÆ„Éá„Éº„Çø„Çµ„Ç§„Ç®„É≥„ÉÜ„Ç£„Çπ„Éà„Å®„Åó„Å¶„ÅÆÂº∑„Åø„ÅØ„Äå„Éò„É´„Çπ„Ç±„Ç¢„Çí„Çè„Åã„Å£„Å¶„ÅÑ„Çã„Äç‰ª•Â§ñ„Å´„ÅØ„ÅÇ„Çä„Åæ„Åõ„Çì„ÄÇ\\n...</td>\n",
       "      <td>1268216404299468800</td>\n",
       "      <td>ja</td>\n",
       "      <td>152</td>\n",
       "      <td>mph_for_doctors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mon Jun 08 04:48:47 +0000 2020</td>\n",
       "      <td>[0, 277]</td>\n",
       "      <td>925</td>\n",
       "      <td>Since 2017, I have had a standing offer: \\n\\nI...</td>\n",
       "      <td>1269853860983525377</td>\n",
       "      <td>en</td>\n",
       "      <td>153</td>\n",
       "      <td>chrisalbon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mon Jun 01 13:08:08 +0000 2020</td>\n",
       "      <td>[0, 270]</td>\n",
       "      <td>912</td>\n",
       "      <td>As part of #AtHomeWithAI, we‚Äôve brought back t...</td>\n",
       "      <td>1267442809520480256</td>\n",
       "      <td>en</td>\n",
       "      <td>321</td>\n",
       "      <td>DeepMind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wed Jun 03 15:25:00 +0000 2020</td>\n",
       "      <td>[0, 220]</td>\n",
       "      <td>647</td>\n",
       "      <td>DeepMind just released a new set of free lectu...</td>\n",
       "      <td>1268202028234407937</td>\n",
       "      <td>en</td>\n",
       "      <td>245</td>\n",
       "      <td>MIT_CSAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tue Jun 02 15:44:42 +0000 2020</td>\n",
       "      <td>[0, 234]</td>\n",
       "      <td>596</td>\n",
       "      <td>If you are blurring faces or info in photos, p...</td>\n",
       "      <td>1267844597956218881</td>\n",
       "      <td>en</td>\n",
       "      <td>198</td>\n",
       "      <td>AnneMunition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wed Jun 03 05:17:36 +0000 2020</td>\n",
       "      <td>[0, 203]</td>\n",
       "      <td>515</td>\n",
       "      <td>I've hired many data scientists. I've also bee...</td>\n",
       "      <td>1268049171413524481</td>\n",
       "      <td>en</td>\n",
       "      <td>27</td>\n",
       "      <td>chrisalbon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fri Jun 05 19:30:00 +0000 2020</td>\n",
       "      <td>[0, 282]</td>\n",
       "      <td>474</td>\n",
       "      <td>This 10-page (PDF) #DataScience Cheat Sheet co...</td>\n",
       "      <td>1268988461366882304</td>\n",
       "      <td>en</td>\n",
       "      <td>194</td>\n",
       "      <td>KirkDBorne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wed Jun 03 16:57:24 +0000 2020</td>\n",
       "      <td>[0, 273]</td>\n",
       "      <td>458</td>\n",
       "      <td>Small observation about ML Twitter:\\n\\nWhen so...</td>\n",
       "      <td>1268225282101481478</td>\n",
       "      <td>en</td>\n",
       "      <td>36</td>\n",
       "      <td>chrisalbon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Tue Jun 02 18:40:00 +0000 2020</td>\n",
       "      <td>[0, 157]</td>\n",
       "      <td>340</td>\n",
       "      <td>Is machine learning racist and sexist? The tec...</td>\n",
       "      <td>1267888713813671936</td>\n",
       "      <td>en</td>\n",
       "      <td>184</td>\n",
       "      <td>Reuters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sat Jun 06 05:01:03 +0000 2020</td>\n",
       "      <td>[0, 32]</td>\n",
       "      <td>304</td>\n",
       "      <td>What bad data science looks like https://t.co/...</td>\n",
       "      <td>1269132171962224640</td>\n",
       "      <td>en</td>\n",
       "      <td>55</td>\n",
       "      <td>dpatil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mon Jun 08 15:30:19 +0000 2020</td>\n",
       "      <td>[0, 276]</td>\n",
       "      <td>291</td>\n",
       "      <td>In this lecture, @ThoreG explains our machine ...</td>\n",
       "      <td>1270015306656817152</td>\n",
       "      <td>en</td>\n",
       "      <td>104</td>\n",
       "      <td>DeepMind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sun Jun 07 22:44:00 +0000 2020</td>\n",
       "      <td>[0, 239]</td>\n",
       "      <td>253</td>\n",
       "      <td>Backpropagation in #MachineLearning and #Finan...</td>\n",
       "      <td>1269762057668198400</td>\n",
       "      <td>en</td>\n",
       "      <td>141</td>\n",
       "      <td>KirkDBorne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sat Jun 06 21:18:07 +0000 2020</td>\n",
       "      <td>[0, 165]</td>\n",
       "      <td>233</td>\n",
       "      <td>People smarter than me have called into questi...</td>\n",
       "      <td>1269378056839467010</td>\n",
       "      <td>en</td>\n",
       "      <td>94</td>\n",
       "      <td>jonathancoulton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Fri Jun 05 00:52:00 +0000 2020</td>\n",
       "      <td>[0, 280]</td>\n",
       "      <td>222</td>\n",
       "      <td>Math for #MachineLearning and #Artificialintel...</td>\n",
       "      <td>1268707106158309376</td>\n",
       "      <td>en</td>\n",
       "      <td>109</td>\n",
       "      <td>KirkDBorne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Wed Jun 03 01:29:48 +0000 2020</td>\n",
       "      <td>[0, 156]</td>\n",
       "      <td>190</td>\n",
       "      <td>Machine Learning for Systems, a perspective fr...</td>\n",
       "      <td>1267991844333346816</td>\n",
       "      <td>en</td>\n",
       "      <td>33</td>\n",
       "      <td>Reza_Zadeh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Fri Jun 05 23:08:53 +0000 2020</td>\n",
       "      <td>[0, 250]</td>\n",
       "      <td>154</td>\n",
       "      <td>Hey @CNBC: a chart of the 1st derivative is no...</td>\n",
       "      <td>1269043544213225478</td>\n",
       "      <td>en</td>\n",
       "      <td>25</td>\n",
       "      <td>peteskomoroch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Fri Jun 05 21:00:00 +0000 2020</td>\n",
       "      <td>[0, 265]</td>\n",
       "      <td>151</td>\n",
       "      <td>[Free 479-page PDF eBook]\\nThe #Mathematics an...</td>\n",
       "      <td>1269011110587445252</td>\n",
       "      <td>en</td>\n",
       "      <td>72</td>\n",
       "      <td>KirkDBorne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sun Jun 07 19:40:00 +0000 2020</td>\n",
       "      <td>[0, 142]</td>\n",
       "      <td>137</td>\n",
       "      <td>Robinson et al. (2020) ‚ÄúTeaching yourself abou...</td>\n",
       "      <td>1269715752237633537</td>\n",
       "      <td>en</td>\n",
       "      <td>53</td>\n",
       "      <td>nataliexdean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Sat Jun 06 15:00:24 +0000 2020</td>\n",
       "      <td>[0, 99]</td>\n",
       "      <td>136</td>\n",
       "      <td>How AI and machine learning are helping to tac...</td>\n",
       "      <td>1269283003680907264</td>\n",
       "      <td>en</td>\n",
       "      <td>44</td>\n",
       "      <td>wef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Mon Jun 08 13:23:00 +0000 2020</td>\n",
       "      <td>[0, 218]</td>\n",
       "      <td>133</td>\n",
       "      <td>Best Online Courses for learning #DataScience ...</td>\n",
       "      <td>1269983268130168832</td>\n",
       "      <td>en</td>\n",
       "      <td>86</td>\n",
       "      <td>KirkDBorne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Sun Jun 07 03:55:03 +0000 2020</td>\n",
       "      <td>[0, 110]</td>\n",
       "      <td>129</td>\n",
       "      <td>üë©üèæ‚Äçüíª Learn about #DataScience in our 5-Part Mi...</td>\n",
       "      <td>1269477949285302278</td>\n",
       "      <td>en</td>\n",
       "      <td>55</td>\n",
       "      <td>WomenWhoCode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Mon Jun 01 14:14:29 +0000 2020</td>\n",
       "      <td>[0, 104]</td>\n",
       "      <td>127</td>\n",
       "      <td>New resources!: https://t.co/TZdtNqGHzz Start ...</td>\n",
       "      <td>1267459507573014528</td>\n",
       "      <td>en</td>\n",
       "      <td>42</td>\n",
       "      <td>joboaler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Wed Jun 03 20:55:28 +0000 2020</td>\n",
       "      <td>[0, 275]</td>\n",
       "      <td>125</td>\n",
       "      <td>Kaggle's micro-courses have been surging in 20...</td>\n",
       "      <td>1268285195146235905</td>\n",
       "      <td>en</td>\n",
       "      <td>38</td>\n",
       "      <td>antgoldbloom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Mon Jun 08 21:00:02 +0000 2020</td>\n",
       "      <td>[0, 255]</td>\n",
       "      <td>123</td>\n",
       "      <td>I'm so excited to welcome our interns for this...</td>\n",
       "      <td>1270098283445145600</td>\n",
       "      <td>en</td>\n",
       "      <td>11</td>\n",
       "      <td>Gaylen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Mon Jun 08 10:58:35 +0000 2020</td>\n",
       "      <td>[0, 97]</td>\n",
       "      <td>116</td>\n",
       "      <td>8 MATLAB cheat sheets for data science https:/...</td>\n",
       "      <td>1269946924586672128</td>\n",
       "      <td>en</td>\n",
       "      <td>40</td>\n",
       "      <td>MATLAB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        created_at display_text_range  favorite_count  \\\n",
       "0   Wed Jun 03 15:19:53 +0000 2020           [0, 143]            9052   \n",
       "1   Tue Jun 02 00:48:31 +0000 2020           [0, 228]            3041   \n",
       "2   Wed Jun 03 16:22:07 +0000 2020           [0, 141]            2119   \n",
       "3   Mon Jun 08 04:48:47 +0000 2020           [0, 277]             925   \n",
       "4   Mon Jun 01 13:08:08 +0000 2020           [0, 270]             912   \n",
       "5   Wed Jun 03 15:25:00 +0000 2020           [0, 220]             647   \n",
       "6   Tue Jun 02 15:44:42 +0000 2020           [0, 234]             596   \n",
       "7   Wed Jun 03 05:17:36 +0000 2020           [0, 203]             515   \n",
       "8   Fri Jun 05 19:30:00 +0000 2020           [0, 282]             474   \n",
       "9   Wed Jun 03 16:57:24 +0000 2020           [0, 273]             458   \n",
       "10  Tue Jun 02 18:40:00 +0000 2020           [0, 157]             340   \n",
       "11  Sat Jun 06 05:01:03 +0000 2020            [0, 32]             304   \n",
       "12  Mon Jun 08 15:30:19 +0000 2020           [0, 276]             291   \n",
       "13  Sun Jun 07 22:44:00 +0000 2020           [0, 239]             253   \n",
       "14  Sat Jun 06 21:18:07 +0000 2020           [0, 165]             233   \n",
       "15  Fri Jun 05 00:52:00 +0000 2020           [0, 280]             222   \n",
       "16  Wed Jun 03 01:29:48 +0000 2020           [0, 156]             190   \n",
       "17  Fri Jun 05 23:08:53 +0000 2020           [0, 250]             154   \n",
       "18  Fri Jun 05 21:00:00 +0000 2020           [0, 265]             151   \n",
       "19  Sun Jun 07 19:40:00 +0000 2020           [0, 142]             137   \n",
       "20  Sat Jun 06 15:00:24 +0000 2020            [0, 99]             136   \n",
       "21  Mon Jun 08 13:23:00 +0000 2020           [0, 218]             133   \n",
       "22  Sun Jun 07 03:55:03 +0000 2020           [0, 110]             129   \n",
       "23  Mon Jun 01 14:14:29 +0000 2020           [0, 104]             127   \n",
       "24  Wed Jun 03 20:55:28 +0000 2020           [0, 275]             125   \n",
       "25  Mon Jun 08 21:00:02 +0000 2020           [0, 255]             123   \n",
       "26  Mon Jun 08 10:58:35 +0000 2020            [0, 97]             116   \n",
       "\n",
       "                                            full_text                   id  \\\n",
       "0   „Ç¢„É°„É™„Ç´„ÅÆ„Éò„É´„Çπ„Ç±„Ç¢‰ºÅÊ•≠„ÅÆÊé°Áî®„ÅåÊ±∫„Åæ„Çä„Åæ„Åó„Åü„ÄÇ\\n\\nÈßÜ„ÅëÂá∫„Åó„Åß„ÅØ„ÅÇ„Çä„Åæ„Åô„Åå„ÄÅ„Éá„Éº„Çø„Çµ„Ç§„Ç®„É≥...  1268200743372275713   \n",
       "1   No masks. No social distancing. But at least t...  1267619067919245314   \n",
       "2   ÁßÅ„ÅÆ„Éá„Éº„Çø„Çµ„Ç§„Ç®„É≥„ÉÜ„Ç£„Çπ„Éà„Å®„Åó„Å¶„ÅÆÂº∑„Åø„ÅØ„Äå„Éò„É´„Çπ„Ç±„Ç¢„Çí„Çè„Åã„Å£„Å¶„ÅÑ„Çã„Äç‰ª•Â§ñ„Å´„ÅØ„ÅÇ„Çä„Åæ„Åõ„Çì„ÄÇ\\n...  1268216404299468800   \n",
       "3   Since 2017, I have had a standing offer: \\n\\nI...  1269853860983525377   \n",
       "4   As part of #AtHomeWithAI, we‚Äôve brought back t...  1267442809520480256   \n",
       "5   DeepMind just released a new set of free lectu...  1268202028234407937   \n",
       "6   If you are blurring faces or info in photos, p...  1267844597956218881   \n",
       "7   I've hired many data scientists. I've also bee...  1268049171413524481   \n",
       "8   This 10-page (PDF) #DataScience Cheat Sheet co...  1268988461366882304   \n",
       "9   Small observation about ML Twitter:\\n\\nWhen so...  1268225282101481478   \n",
       "10  Is machine learning racist and sexist? The tec...  1267888713813671936   \n",
       "11  What bad data science looks like https://t.co/...  1269132171962224640   \n",
       "12  In this lecture, @ThoreG explains our machine ...  1270015306656817152   \n",
       "13  Backpropagation in #MachineLearning and #Finan...  1269762057668198400   \n",
       "14  People smarter than me have called into questi...  1269378056839467010   \n",
       "15  Math for #MachineLearning and #Artificialintel...  1268707106158309376   \n",
       "16  Machine Learning for Systems, a perspective fr...  1267991844333346816   \n",
       "17  Hey @CNBC: a chart of the 1st derivative is no...  1269043544213225478   \n",
       "18  [Free 479-page PDF eBook]\\nThe #Mathematics an...  1269011110587445252   \n",
       "19  Robinson et al. (2020) ‚ÄúTeaching yourself abou...  1269715752237633537   \n",
       "20  How AI and machine learning are helping to tac...  1269283003680907264   \n",
       "21  Best Online Courses for learning #DataScience ...  1269983268130168832   \n",
       "22  üë©üèæ‚Äçüíª Learn about #DataScience in our 5-Part Mi...  1269477949285302278   \n",
       "23  New resources!: https://t.co/TZdtNqGHzz Start ...  1267459507573014528   \n",
       "24  Kaggle's micro-courses have been surging in 20...  1268285195146235905   \n",
       "25  I'm so excited to welcome our interns for this...  1270098283445145600   \n",
       "26  8 MATLAB cheat sheets for data science https:/...  1269946924586672128   \n",
       "\n",
       "   lang  retweet_count      screen_name  \n",
       "0    ja            559  mph_for_doctors  \n",
       "1    en            647   YossiGestetner  \n",
       "2    ja            152  mph_for_doctors  \n",
       "3    en            153       chrisalbon  \n",
       "4    en            321         DeepMind  \n",
       "5    en            245        MIT_CSAIL  \n",
       "6    en            198     AnneMunition  \n",
       "7    en             27       chrisalbon  \n",
       "8    en            194       KirkDBorne  \n",
       "9    en             36       chrisalbon  \n",
       "10   en            184          Reuters  \n",
       "11   en             55           dpatil  \n",
       "12   en            104         DeepMind  \n",
       "13   en            141       KirkDBorne  \n",
       "14   en             94  jonathancoulton  \n",
       "15   en            109       KirkDBorne  \n",
       "16   en             33       Reza_Zadeh  \n",
       "17   en             25    peteskomoroch  \n",
       "18   en             72       KirkDBorne  \n",
       "19   en             53     nataliexdean  \n",
       "20   en             44              wef  \n",
       "21   en             86       KirkDBorne  \n",
       "22   en             55     WomenWhoCode  \n",
       "23   en             42         joboaler  \n",
       "24   en             38     antgoldbloom  \n",
       "25   en             11           Gaylen  \n",
       "26   en             40           MATLAB  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.io.json.json_normalize(popular_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post infomation about tweets on Wordpress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text_file(path):\n",
    "    f = open(path)\n",
    "    data = f.read() \n",
    "    f.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_html_for_tweet_embeded(popular_tweets):\n",
    "    html_format_to_embed_tweet = read_text_file('text/html_format_to_embed_tweet.txt')\n",
    "    html_for_tweets_ja = ''\n",
    "    html_for_tweets_en = ''\n",
    "    for tweet in popular_tweets:\n",
    "        tweet_id = tweet['id']\n",
    "        screen_name = tweet['screen_name']\n",
    "        language = tweet['lang']\n",
    "        html_to_be_added = html_format_to_embed_tweet.format(\n",
    "                SCREEN_NAME=screen_name,\n",
    "                ID=tweet_id\n",
    "        ) + '\\n'\n",
    "        if language == 'ja':\n",
    "            html_for_tweets_ja += html_to_be_added\n",
    "        elif language == 'en':\n",
    "            html_for_tweets_en += html_to_be_added\n",
    "    return {\n",
    "        'ja': html_for_tweets_ja,\n",
    "        'en': html_for_tweets_en\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_content_as_html_for_wp(popular_tweets):\n",
    "    html_for_tweets = make_html_for_tweet_embeded(popular_tweets)\n",
    "    body_for_wp_post = read_text_file('text/body_for_wp_post.txt')\n",
    "    body_for_wp_post = body_for_wp_post.format(\n",
    "        YEAR=params_to_be_set['YEAR'], \n",
    "        S_MONTH=params_to_be_set['S_MONTH'],\n",
    "        S_DATE=params_to_be_set['S_DATE'],\n",
    "        E_MONTH=params_to_be_set['E_MONTH'],\n",
    "        E_DATE=params_to_be_set['E_DATE'],\n",
    "        TWEETS_JA=html_for_tweets['ja'],\n",
    "        TWEETS_EN=html_for_tweets['en']\n",
    "    )\n",
    "    return body_for_wp_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(make_content_as_html_for_wp(popular_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_article(params, tweets, debug=False):\n",
    "    user_name = params['WP_USERNAME']\n",
    "    pass_word = params['WP_PASSWORD']\n",
    "    payload = {\n",
    "        \"status\": params['STATUS'],\n",
    "        \"slug\": params['SLUG'],\n",
    "        \"title\": params['TITLE'],\n",
    "        \"content\": make_content_as_html_for_wp(popular_tweets),\n",
    "        \"date\": datetime.now().isoformat(),\n",
    "        \"categories\": params['CATEGORY'],\n",
    "    }\n",
    "    if params['MEDIA_ID'] is not None:\n",
    "        payload['featured_media'] = params['MEDIA_ID']\n",
    "    res = requests.post(\n",
    "        urljoin(params['WP_URL'], \"wp-json/wp/v2/posts\"),\n",
    "        data=json.dumps(payload),\n",
    "        headers={'Content-type': \"application/json\"},\n",
    "        auth=(user_name, pass_word)\n",
    "    )\n",
    "    if debug:\n",
    "        print('----------\\nTitle: „Äå{}„Äç„ÅÆÊäïÁ®ø„É™„ÇØ„Ç®„Çπ„ÉàÁµêÊûú:{}'.format(params['TITLE'], repr(res.status_code)))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Title: „Äå„Éá„Éº„Çø„Çµ„Ç§„Ç®„É≥„Çπ„ÉªÊ©üÊ¢∞Â≠¶Áøí Twiiter ÊäïÁ®ø„Åæ„Å®„ÇÅ 2020/06/01-2020/06/09„Äç„ÅÆÊäïÁ®ø„É™„ÇØ„Ç®„Çπ„ÉàÁµêÊûú:201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [201]>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_article(params, tweets, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requests.get(urljoin(params['WP_URL'], \"wp-json/wp/v2/categories\")).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
